{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "import time\n",
    "import pandas_ta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 Membership Reconstruction\n",
    "\n",
    "This section builds a **daily membership history** of the S&P 500 using the\n",
    "[Financial Modeling Prep (FMP) API](https://financialmodelingprep.com/).\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Fetch current and historical constituents**\n",
    "   - `URL_CUR`: current S&P 500 tickers.\n",
    "   - `URL_HIS`: historical add/remove events with dates.\n",
    "\n",
    "2. **Clean and prepare the historical dataset**\n",
    "   - Convert `date` to `datetime` and sort chronologically.\n",
    "   - Split into two event streams:\n",
    "     - **ADD** events → new tickers added.\n",
    "     - **REMOVE** events → tickers removed.\n",
    "\n",
    "3. **Combine all events**\n",
    "   - Concatenate adds and removes into a single `events` DataFrame.\n",
    "   - Each row = `(date, ticker, event)`.\n",
    "\n",
    "4. **Build a daily timeline**\n",
    "   - Define a date range from 12 years ago to today (`START` → `END`).\n",
    "   - For each day, initialize empty sets of `ADD` and `REMOVE` events.\n",
    "   - Populate the dictionary with the tickers added/removed on that date.\n",
    "\n",
    "5. **Reconstruct membership backwards in time**\n",
    "   - Start from the **current membership list**.\n",
    "   - For each day (going backwards):\n",
    "     - Record the current member set as a snapshot.\n",
    "     - Apply that day’s **ADD** and **REMOVE** events in reverse:\n",
    "       - Subtract tickers that were added on that day.\n",
    "       - Add tickers that were removed on that day.\n",
    "   - This produces a consistent set of tickers for every date.\n",
    "\n",
    "6. **Create the final daily membership table**\n",
    "   - Explode the daily snapshots so that each row = `(date, ticker)`.\n",
    "   - This `long` DataFrame shows which tickers were in the S&P 500 on each day.\n",
    "\n",
    "### Output\n",
    "\n",
    "- `events`: all add/remove actions with dates.  \n",
    "- `snapshots`: membership sets per day (before exploding).  \n",
    "- `long`: normalized daily membership history with two columns:\n",
    "  - `date`\n",
    "  - `ticker`\n",
    "\n",
    "This dataset can now be joined with stock prices, fundamentals, or other\n",
    "metrics to run time-aware analyses of S&P 500 membership.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "API_KEY = \"\"\n",
    "URL_CUR = f\"https://financialmodelingprep.com/api/v3/sp500_constituent?apikey={API_KEY}\"\n",
    "URL_HIS = f\"https://financialmodelingprep.com/api/v3/historical/sp500_constituent?apikey={API_KEY}\"\n",
    "\n",
    "END   = pd.to_datetime(date.today())\n",
    "START = END - pd.DateOffset(years=12)  # change to full history if you want\n",
    "\n",
    "cur = pd.DataFrame(requests.get(URL_CUR, timeout=60).json())\n",
    "his = pd.DataFrame(requests.get(URL_HIS, timeout=60).json())\n",
    "his[\"date\"] = pd.to_datetime(his[\"date\"], errors=\"coerce\")\n",
    "his = his.dropna(subset=[\"date\"]).sort_values(\"date\")\n",
    "\n",
    "adds = his.loc[his[\"symbol\"].notna(), [\"date\",\"symbol\"]].rename(columns={\"symbol\":\"ticker\"})\n",
    "adds[\"event\"] = \"ADD\"\n",
    "remv = his.loc[his.get(\"removedTicker\").notna(), [\"date\",\"removedTicker\"]].rename(columns={\"removedTicker\":\"ticker\"})\n",
    "remv[\"event\"] = \"REMOVE\"\n",
    "events = pd.concat([adds, remv], ignore_index=True).query(\"date <= @END\").sort_values(\"date\")\n",
    "\n",
    "current = set(cur[\"symbol\"].astype(str))\n",
    "days = pd.date_range(START, END, freq=\"D\")\n",
    "by_day = {d: {\"ADD\": set(), \"REMOVE\": set()} for d in days}\n",
    "for d, g in events.groupby(\"date\"):\n",
    "    if d in by_day:\n",
    "        by_day[d][\"ADD\"]    = set(g.loc[g[\"event\"]==\"ADD\",\"ticker\"])\n",
    "        by_day[d][\"REMOVE\"] = set(g.loc[g[\"event\"]==\"REMOVE\",\"ticker\"])\n",
    "\n",
    "members = set(current)\n",
    "snapshots = []\n",
    "for d in sorted(days, reverse=True):\n",
    "    snapshots.append({\"date\": d, \"members\": tuple(sorted(members))})\n",
    "    ev = by_day.get(d, {\"ADD\": set(), \"REMOVE\": set()})\n",
    "    members -= ev[\"ADD\"]\n",
    "    members |= ev[\"REMOVE\"]\n",
    "\n",
    "long = (pd.DataFrame(snapshots)\n",
    "          .explode(\"members\")\n",
    "          .rename(columns={\"members\":\"ticker\"})\n",
    "          .dropna(subset=[\"ticker\"])\n",
    "          .reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>ABT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207441</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>YHOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207442</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>YUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207443</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>ZBH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207444</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>ZION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207445</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2207446 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date ticker\n",
       "0       2025-09-26      A\n",
       "1       2025-09-26   AAPL\n",
       "2       2025-09-26   ABBV\n",
       "3       2025-09-26   ABNB\n",
       "4       2025-09-26    ABT\n",
       "...            ...    ...\n",
       "2207441 2013-09-26   YHOO\n",
       "2207442 2013-09-26    YUM\n",
       "2207443 2013-09-26    ZBH\n",
       "2207444 2013-09-26   ZION\n",
       "2207445 2013-09-26    ZTS\n",
       "\n",
       "[2207446 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canonical Ticker Mapping (CIK-aware) with Safe Rate Limiting\n",
    "\n",
    "This block creates a **canonical symbol** per company (CIK) and maps every `(date, ticker)` row in your `long` membership table to that canonical, handling **renames**, **reused tickers**, and **dot/dash variants**—while respecting FMP’s ~300 calls/min limit.\n",
    "\n",
    "### What it pulls\n",
    "- **`/api/v4/symbol_change`** → full rename graph (`symbol` → `newsymbol`, with `date`).\n",
    "- **`/api/v3/profile/{sym}`** (rate-limited) → `cik`, `companyName` per symbol.\n",
    "\n",
    "### Why canonicalization?\n",
    "- Vendor symbol strings change (e.g., `BRK.B` ↔ `BRK-B`) and tickers are occasionally **reused** by different companies across time.  \n",
    "- **CIK** is the stable company identity. Canonicalization ensures historical joins (prices, fundamentals, events) refer to the same economic entity.\n",
    "\n",
    "### Pipeline\n",
    "1. **Normalize symbols**  \n",
    "   Uppercase, trim, convert `.`↔`-` to a standard form (`norm`), but preserve the user-facing variant (`variant_like`) to match your original style later.\n",
    "\n",
    "2. **Load rename graph**  \n",
    "   From `symbol_change`, keep `symbol`, `newsymbol`, `date`. Sort by (`symbol`, `date`).  \n",
    "   Build a **terminal descendant** map: repeatedly follow last hops `symbol → newsymbol` to the final symbol (latest rename).\n",
    "\n",
    "3. **Collect symbols to profile**  \n",
    "   Union of:\n",
    "   - `long[\"ticker\"]` (your membership table),\n",
    "   - all `symbol_change.symbol` and `symbol_change.newsymbol`,\n",
    "   - all **terminal descendants** (helps pick the latest, most recognizable ticker).  \n",
    "   Fetch profiles **≤290 calls/min** with retry & backoff to get **CIK** per symbol.\n",
    "\n",
    "4. **Choose a canonical per CIK**\n",
    "   - If there were **same-CIK renames**, pick the **latest** `newsymbol` for that CIK → `canonical_norm`.\n",
    "   - Otherwise, fall back to the **last-seen membership symbol** for that CIK in your data.\n",
    "\n",
    "5. **Map each membership row**\n",
    "   - Attach `CIK` via the profiled symbol; if missing, try the **terminal descendant’s** CIK (fixes some reused-ticker cases).\n",
    "   - Set `canonical_norm` from the CIK→canonical map; if still missing, fall back to the **terminal descendant**; else keep original.\n",
    "   - Produce a display-friendly `ticker_latest` using `variant_like` to mirror the user’s original dot/dash style.\n",
    "\n",
    "### Output\n",
    "- **`long_latest`** with columns:\n",
    "  - `date`\n",
    "  - `ticker_membership` (original ticker from `long`)\n",
    "  - `CIK` (stable company identifier)\n",
    "  - `ticker_latest` (canonical latest ticker, styled to match original dot/dash preference)\n",
    "\n",
    "### Rate limiting & resilience\n",
    "- **Leaky-bucket** limiter at `CALLS_PER_MIN = 290` (under the 300/min cap).\n",
    "- **Retries** with exponential backoff on 429/5xx/timeouts.\n",
    "- Uses a single `requests.Session()` for connection reuse.\n",
    "\n",
    "### Edge cases handled\n",
    "- **Ticker reuse**: resolve by CIK; if unknown, fall back to rename terminal.\n",
    "- **Multiple hops** (A→B→C): terminal descendant picks `C`.\n",
    "- **Dot/dash variants**: normalize internally, but align presentation to the user’s original convention.\n",
    "- **Missing/NaN**: safe normalization and guarded merges.\n",
    "\n",
    "### Join tips\n",
    "Use `ticker_latest` for **current-name joins** (e.g., latest reports, news), and `CIK` for **entity-stable joins** across time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit pause 42.3s (processed 290/9055)\n",
      "Rate limit pause 46.6s (processed 580/9055)\n",
      "Rate limit pause 47.1s (processed 870/9055)\n",
      "Rate limit pause 47.5s (processed 1160/9055)\n",
      "Rate limit pause 36.2s (processed 1450/9055)\n",
      "Rate limit pause 39.5s (processed 1740/9055)\n",
      "Rate limit pause 47.8s (processed 2030/9055)\n",
      "Rate limit pause 45.5s (processed 2320/9055)\n",
      "Rate limit pause 45.5s (processed 2610/9055)\n",
      "Rate limit pause 33.9s (processed 2900/9055)\n",
      "Rate limit pause 45.7s (processed 3190/9055)\n",
      "Rate limit pause 47.6s (processed 3480/9055)\n",
      "Rate limit pause 47.9s (processed 3770/9055)\n",
      "Rate limit pause 45.6s (processed 4060/9055)\n",
      "Rate limit pause 42.8s (processed 4350/9055)\n",
      "Rate limit pause 43.6s (processed 4640/9055)\n",
      "Rate limit pause 44.3s (processed 4930/9055)\n",
      "Rate limit pause 48.9s (processed 5220/9055)\n",
      "Rate limit pause 49.4s (processed 5510/9055)\n",
      "Rate limit pause 40.4s (processed 5800/9055)\n",
      "Rate limit pause 42.3s (processed 6090/9055)\n",
      "Rate limit pause 48.4s (processed 6380/9055)\n",
      "Rate limit pause 45.5s (processed 6670/9055)\n",
      "Rate limit pause 22.4s (processed 6960/9055)\n",
      "Rate limit pause 1.6s (processed 7250/9055)\n",
      "Rate limit pause 0.5s (processed 7540/9055)\n",
      "Rate limit pause 6.2s (processed 7830/9055)\n",
      "Rate limit pause 4.4s (processed 8120/9055)\n",
      "Rate limit pause 5.0s (processed 8410/9055)\n",
      "Rate limit pause 1.3s (processed 8700/9055)\n",
      "Rate limit pause 6.7s (processed 8990/9055)\n",
      "Rows: 2207446\n",
      "        date ticker_membership         CIK ticker_latest\n",
      "0 2025-09-26                 A  0001090872             A\n",
      "1 2025-09-26              AAPL  0000320193          AAPL\n",
      "2 2025-09-26              ABBV  0001551152          ABBV\n",
      "3 2025-09-26              ABNB  0001559720          ABNB\n",
      "4 2025-09-26               ABT  0000001800           ABT\n",
      "5 2025-09-26              ACGL  0000947484          ACGL\n",
      "6 2025-09-26               ACN  0001467373           ACN\n",
      "7 2025-09-26              ADBE  0000796343          ADBE\n",
      "8 2025-09-26               ADI  0000006281           ADI\n",
      "9 2025-09-26               ADM  0000007084           ADM\n"
     ]
    }
   ],
   "source": [
    "# ================== Accurate canonical mapping with 290 calls/min ==================\n",
    "import time, math, requests\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "API_KEY = \"\"\n",
    "URL_SC  = f\"https://financialmodelingprep.com/api/v4/symbol_change?apikey={API_KEY}\"\n",
    "URL_PROF= \"https://financialmodelingprep.com/api/v3/profile/{sym}?apikey=\" + API_KEY\n",
    "\n",
    "# ---- Rate limit config ----\n",
    "CALLS_PER_MIN = 290     # safety below the 300/min cap\n",
    "MAX_RETRY     = 3\n",
    "TIMEOUT       = 30\n",
    "\n",
    "def norm(s):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)): return None\n",
    "    return str(s).strip().upper().replace(\".\", \"-\")\n",
    "\n",
    "def variant_like(original, normalized):\n",
    "    if normalized is None: return None\n",
    "    out = normalized\n",
    "    if \".\" in original and \"-\" in out: out = out.replace(\"-\", \".\")\n",
    "    if \"-\" in original and \".\" in out: out = out.replace(\".\", \"-\")\n",
    "    return out\n",
    "\n",
    "# -------- 1) Pull symbol_change once (no rate limit issues) --------\n",
    "sc = pd.DataFrame(requests.get(URL_SC, timeout=60).json())\n",
    "sc.columns = [c.lower() for c in sc.columns]\n",
    "if \"newsymbol\" not in sc.columns and \"newSymbol\" in sc.columns:\n",
    "    sc[\"newsymbol\"] = sc[\"newSymbol\"]\n",
    "if \"symbol\" not in sc.columns and \"oldsymbol\" in sc.columns:\n",
    "    sc = sc.rename(columns={\"oldsymbol\":\"symbol\"})\n",
    "\n",
    "sc = sc[[\"symbol\",\"newsymbol\",\"date\"]].dropna(subset=[\"symbol\",\"newsymbol\"])\n",
    "sc[\"date\"] = pd.to_datetime(sc[\"date\"], errors=\"coerce\")\n",
    "sc = sc.dropna(subset=[\"date\"]).copy()\n",
    "sc[\"symbol\"]    = sc[\"symbol\"].map(norm)\n",
    "sc[\"newsymbol\"] = sc[\"newsymbol\"].map(norm)\n",
    "sc = sc.sort_values([\"symbol\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "# Precompute terminal descendant map (latest-hop transitive closure)\n",
    "_last_hop = sc.drop_duplicates(\"symbol\", keep=\"last\").set_index(\"symbol\")[\"newsymbol\"].to_dict()\n",
    "def terminal(sym):\n",
    "    cur, seen = sym, set()\n",
    "    while cur in _last_hop and cur not in seen:\n",
    "        seen.add(cur); cur = _last_hop[cur]\n",
    "    return cur\n",
    "\n",
    "# -------- 2) Build symbol set to profile (rate-limited) --------\n",
    "long2 = long.copy()\n",
    "long2[\"date\"] = pd.to_datetime(long2[\"date\"], errors=\"coerce\")\n",
    "long2 = long2.dropna(subset=[\"date\"]).reset_index(drop=True)\n",
    "long2[\"ticker_norm\"] = long2[\"ticker\"].map(norm)\n",
    "\n",
    "symbols_needed = sorted(\n",
    "    set(long2[\"ticker_norm\"].dropna())\n",
    "    | set(sc[\"symbol\"])\n",
    "    | set(sc[\"newsymbol\"])\n",
    "    | {terminal(s) for s in set(sc[\"symbol\"])}  # terminals help choose canonicals\n",
    ")\n",
    "\n",
    "# -------- 3) Rate-limited profile fetch (<=290/min) --------\n",
    "def fetch_profiles_rate_limited(symbols):\n",
    "    rows = []\n",
    "    calls_in_window = 0\n",
    "    window_start = time.time()\n",
    "    with requests.Session() as s:\n",
    "        for i, sym in enumerate(symbols, start=1):\n",
    "            # simple leaky-bucket limiter\n",
    "            now = time.time()\n",
    "            elapsed = now - window_start\n",
    "            if calls_in_window >= CALLS_PER_MIN and elapsed < 60:\n",
    "                sleep_for = 60 - elapsed\n",
    "                print(f\"Rate limit pause {sleep_for:.1f}s (processed {i-1}/{len(symbols)})\")\n",
    "                time.sleep(sleep_for)\n",
    "                window_start = time.time()\n",
    "                calls_in_window = 0\n",
    "\n",
    "            # resilient GET with backoff\n",
    "            url = URL_PROF.format(sym=sym)\n",
    "            backoff = 2.0\n",
    "            payload = None\n",
    "            for attempt in range(1, MAX_RETRY+1):\n",
    "                try:\n",
    "                    r = s.get(url, timeout=TIMEOUT)\n",
    "                    if r.ok:\n",
    "                        js = r.json()\n",
    "                        if isinstance(js, list) and js:\n",
    "                            payload = js[0]\n",
    "                        break\n",
    "                    if r.status_code in (429,500,502,503,504) and attempt < MAX_RETRY:\n",
    "                        time.sleep(backoff); backoff *= 2; continue\n",
    "                    break\n",
    "                except requests.RequestException:\n",
    "                    if attempt < MAX_RETRY:\n",
    "                        time.sleep(backoff); backoff *= 2; continue\n",
    "                    break\n",
    "            calls_in_window += 1\n",
    "\n",
    "            rows.append({\n",
    "                \"symbol_norm\": sym,\n",
    "                \"CIK\": (payload or {}).get(\"cik\"),\n",
    "                \"companyName\": (payload or {}).get(\"companyName\")\n",
    "            })\n",
    "    return pd.DataFrame(rows).drop_duplicates(\"symbol_norm\", keep=\"last\")\n",
    "\n",
    "profiles = fetch_profiles_rate_limited(symbols_needed)\n",
    "sym2cik   = profiles.set_index(\"symbol_norm\")[\"CIK\"].to_dict()\n",
    "\n",
    "# -------- 4) Identify same-CIK renames; build canonical per CIK --------\n",
    "sc[\"old_cik\"] = sc[\"symbol\"].map(sym2cik)\n",
    "sc[\"new_cik\"] = sc[\"newsymbol\"].map(sym2cik)\n",
    "same_cik = sc.dropna(subset=[\"old_cik\",\"new_cik\"]).query(\"old_cik == new_cik\")\n",
    "\n",
    "# Latest same-CIK rename decides the canonical if present\n",
    "latest_same = (\n",
    "    same_cik.sort_values(\"date\")\n",
    "            .groupby(\"old_cik\", as_index=False)\n",
    "            .tail(1)[[\"old_cik\",\"newsymbol\"]]\n",
    "            .rename(columns={\"old_cik\":\"CIK\",\"newsymbol\":\"canonical_norm\"})\n",
    ")\n",
    "\n",
    "# Fallback per CIK: last-seen membership symbol in your data\n",
    "last_seen = (\n",
    "    long2.assign(CIK = long2[\"ticker_norm\"].map(sym2cik))\n",
    "        .dropna(subset=[\"CIK\"])\n",
    "        .sort_values([\"CIK\",\"date\"])\n",
    "        .groupby(\"CIK\", as_index=False)\n",
    "        .tail(1)[[\"CIK\",\"ticker_norm\"]]\n",
    "        .rename(columns={\"ticker_norm\":\"last_seen_norm\"})\n",
    ")\n",
    "\n",
    "canon = latest_same.merge(last_seen, on=\"CIK\", how=\"outer\")\n",
    "canon[\"canonical_norm\"] = canon[\"canonical_norm\"].fillna(canon[\"last_seen_norm\"])\n",
    "canon = canon[[\"CIK\",\"canonical_norm\"]].dropna().drop_duplicates(\"CIK\", keep=\"last\")\n",
    "\n",
    "# -------- 5) Map every row to canonical; if CIK unknown, fall back to terminal descendant --------\n",
    "long_map = long2.copy()\n",
    "long_map[\"CIK\"] = long_map[\"ticker_norm\"].map(sym2cik)\n",
    "\n",
    "# If CIK missing, try to inherit from terminal (often covers reused tickers cleanly)\n",
    "if long_map[\"CIK\"].isna().any():\n",
    "    term_map = {sym: terminal(sym) for sym in long_map[\"ticker_norm\"].dropna().unique()}\n",
    "    term_cik = {sym: sym2cik.get(t) for sym, t in term_map.items()}\n",
    "    mask = long_map[\"CIK\"].isna()\n",
    "    long_map.loc[mask, \"CIK\"] = long_map.loc[mask, \"ticker_norm\"].map(term_cik)\n",
    "\n",
    "# Attach canonical per known CIK\n",
    "long_map = long_map.merge(canon, on=\"CIK\", how=\"left\")\n",
    "\n",
    "# Final canonical: prefer CIK canonical; else terminal(symbol); else keep membership\n",
    "long_map[\"canonical_norm\"] = long_map.apply(\n",
    "    lambda r: r[\"canonical_norm\"]\n",
    "              if pd.notna(r[\"canonical_norm\"])\n",
    "              else terminal(r[\"ticker_norm\"]) if pd.notna(r[\"ticker_norm\"]) else r[\"ticker_norm\"],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "long_map[\"ticker_latest\"] = [\n",
    "    variant_like(mem, can) for mem, can in zip(long_map[\"ticker\"], long_map[\"canonical_norm\"])\n",
    "]\n",
    "\n",
    "long_latest = (\n",
    "    long_map.rename(columns={\"ticker\":\"ticker_membership\"})\n",
    "            [[\"date\",\"ticker_membership\",\"CIK\",\"ticker_latest\"]]\n",
    ")\n",
    "\n",
    "# -------- 6) Quick sanity prints --------\n",
    "print(\"Rows:\", len(long_latest))\n",
    "print(long_latest.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker_membership</th>\n",
       "      <th>CIK</th>\n",
       "      <th>ticker_latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>A</td>\n",
       "      <td>0001090872</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0000320193</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>0001551152</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>0001559720</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>ABT</td>\n",
       "      <td>0000001800</td>\n",
       "      <td>ABT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207441</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>YHOO</td>\n",
       "      <td>None</td>\n",
       "      <td>YHOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207442</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>YUM</td>\n",
       "      <td>0001041061</td>\n",
       "      <td>YUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207443</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>ZBH</td>\n",
       "      <td>0001136869</td>\n",
       "      <td>ZBH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207444</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>ZION</td>\n",
       "      <td>0000109380</td>\n",
       "      <td>ZION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207445</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>0001555280</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2207446 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date ticker_membership         CIK ticker_latest\n",
       "0       2025-09-26                 A  0001090872             A\n",
       "1       2025-09-26              AAPL  0000320193          AAPL\n",
       "2       2025-09-26              ABBV  0001551152          ABBV\n",
       "3       2025-09-26              ABNB  0001559720          ABNB\n",
       "4       2025-09-26               ABT  0000001800           ABT\n",
       "...            ...               ...         ...           ...\n",
       "2207441 2013-09-26              YHOO        None          YHOO\n",
       "2207442 2013-09-26               YUM  0001041061           YUM\n",
       "2207443 2013-09-26               ZBH  0001136869           ZBH\n",
       "2207444 2013-09-26              ZION  0000109380          ZION\n",
       "2207445 2013-09-26               ZTS  0001555280           ZTS\n",
       "\n",
       "[2207446 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Unique Company Profiles for `ticker_latest` (≤290 calls/min)\n",
    "\n",
    "This block pulls **company profile metadata** from FMP for each unique `ticker_latest`\n",
    "in your `long_latest` table, with **rate limiting**, **retry/backoff**, and a\n",
    "**dot ↔ hyphen** fallback (e.g., `BRK.B` ⇄ `BRK-B`).\n",
    "\n",
    "### Why this exists\n",
    "- You’ve already mapped each membership row to a **latest/canonical ticker** (`ticker_latest`).\n",
    "- This step enriches those latest tickers with **companyName, sector, currency, active flag, CIK**.\n",
    "\n",
    "### Key behaviors\n",
    "- **Rate limit**: caps outbound requests at `CALLS_PER_MIN` (default 290) to stay under FMP’s 300/minute cap.\n",
    "- **Retries**: on 429/5xx/timeouts, retries with exponential backoff (up to `MAX_RETRY`).\n",
    "- **Variant fallback**: if `profile/{symbol}` misses, it tries the swapped variant (`.` ↔ `-`) once.\n",
    "- **Deduping**: only fetches **unique** `ticker_latest` symbols; drops duplicate responses by `symbol`.\n",
    "- **Column normalization**: renames `cik` → `CIK`, and prefers the API’s `symbol` (`hit_symbol`) over the queried one.\n",
    "\n",
    "### Inputs\n",
    "- `long_latest`: DataFrame with at least `ticker_latest` (uppercase/dedup handled inside the function).\n",
    "\n",
    "### Outputs\n",
    "- `profiles_df`: one row per symbol with:\n",
    "  - `symbol` (API-reported; falls back to `queried_symbol` if no hit)\n",
    "  - `companyName`\n",
    "  - `sector`\n",
    "  - `currency`\n",
    "  - `isActivelyTrading`\n",
    "  - `CIK`\n",
    "  - `queried_symbol` (what you asked for)\n",
    "  - `hit_symbol` (what the API returned, if any)\n",
    "\n",
    "### Flow\n",
    "1. **Collect unique** `ticker_latest` → uppercase, strip, deduplicate.\n",
    "2. **For each symbol**:\n",
    "   - Call `GET /api/v3/profile/{symbol}` (retry/backoff).\n",
    "   - If empty, **swap variant** and try again (counts toward rate limit).\n",
    "3. **Assemble row** with `KEEP_COLS` + query/hit symbols.\n",
    "4. **Normalize & dedupe**:\n",
    "   - Prefer `hit_symbol`→`symbol`; rename `cik`→`CIK`.\n",
    "   - Drop exact duplicates on `symbol`.\n",
    "5. **Return** tidy `profiles_df` (ready to save or join).\n",
    "\n",
    "### Join tip\n",
    "To enrich membership rows:\n",
    "```python\n",
    "long_latest_enriched = long_latest.merge(\n",
    "    profiles_df.rename(columns={\"symbol\": \"ticker_latest\"}),\n",
    "    on=\"ticker_latest\",\n",
    "    how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique latest tickers to fetch: 728\n",
      "Fetched 100/728\n",
      "Fetched 200/728\n",
      "Pausing 48.8s to respect 290/min (done 290/728)\n",
      "Fetched 300/728\n",
      "Fetched 400/728\n",
      "Fetched 500/728\n",
      "Pausing 47.7s to respect 290/min (done 580/728)\n",
      "Fetched 600/728\n",
      "Fetched 700/728\n",
      "Fetched 728/728\n",
      "Profiles fetched: 728\n",
      "  symbol                 companyName             sector currency  \\\n",
      "0      A  Agilent Technologies, Inc.         Healthcare      USD   \n",
      "1   AAPL                  Apple Inc.         Technology      USD   \n",
      "2   ABBV                 AbbVie Inc.         Healthcare      USD   \n",
      "3   ABNB                Airbnb, Inc.  Consumer Cyclical      USD   \n",
      "4    ABT         Abbott Laboratories         Healthcare      USD   \n",
      "\n",
      "  isActivelyTrading         CIK queried_symbol hit_symbol  \n",
      "0              True  0001090872              A          A  \n",
      "1              True  0000320193           AAPL       AAPL  \n",
      "2              True  0001551152           ABBV       ABBV  \n",
      "3              True  0001559720           ABNB       ABNB  \n",
      "4              True  0000001800            ABT        ABT  \n"
     ]
    }
   ],
   "source": [
    "# ================== Fetch unique company profiles for ticker_latest (≤290 calls/min) ==================\n",
    "import time, math, requests\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = \"\"\n",
    "\n",
    "CALLS_PER_MIN = 290      # stay under your 300/min cap\n",
    "MAX_RETRY     = 3\n",
    "TIMEOUT       = 30\n",
    "\n",
    "KEEP_COLS = [\"symbol\", \"companyName\", \"sector\", \"currency\", \"isActivelyTrading\", \"cik\"]\n",
    "\n",
    "def swap_variant(sym: str) -> str:\n",
    "    # e.g., BRK.B <-> BRK-B\n",
    "    if \".\" in sym: return sym.replace(\".\", \"-\")\n",
    "    if \"-\" in sym: return sym.replace(\"-\", \".\")\n",
    "    return sym\n",
    "\n",
    "def fetch_profiles_for_latest(long_latest: pd.DataFrame,\n",
    "                              calls_per_min: int = CALLS_PER_MIN) -> pd.DataFrame:\n",
    "    # 1) unique latest tickers (dropna, strip)\n",
    "    symbols = (\n",
    "        long_latest[\"ticker_latest\"]\n",
    "        .dropna()\n",
    "        .map(lambda s: str(s).strip().upper())\n",
    "        .drop_duplicates()\n",
    "        .tolist()\n",
    "    )\n",
    "    print(f\"Unique latest tickers to fetch: {len(symbols)}\")\n",
    "\n",
    "    rows = []\n",
    "    calls_in_window = 0\n",
    "    window_start = time.time()\n",
    "\n",
    "    with requests.Session() as s:\n",
    "        for i, sym in enumerate(symbols, start=1):\n",
    "\n",
    "            # --- rate limit: ≤ calls_per_min per rolling minute\n",
    "            now = time.time()\n",
    "            elapsed = now - window_start\n",
    "            if calls_in_window >= calls_per_min and elapsed < 60:\n",
    "                sleep_for = 60 - elapsed\n",
    "                print(f\"Pausing {sleep_for:.1f}s to respect {calls_per_min}/min (done {i-1}/{len(symbols)})\")\n",
    "                time.sleep(sleep_for)\n",
    "                window_start = time.time()\n",
    "                calls_in_window = 0\n",
    "\n",
    "            def _try_one(ticker: str):\n",
    "                url = f\"https://financialmodelingprep.com/api/v3/profile/{ticker}?apikey={API_KEY}\"\n",
    "                backoff = 2.0\n",
    "                for attempt in range(1, MAX_RETRY + 1):\n",
    "                    try:\n",
    "                        r = s.get(url, timeout=TIMEOUT)\n",
    "                        if r.ok:\n",
    "                            js = r.json()\n",
    "                            return js if isinstance(js, list) else None\n",
    "                        # retry on rate/server errors\n",
    "                        if r.status_code in (429, 500, 502, 503, 504) and attempt < MAX_RETRY:\n",
    "                            time.sleep(backoff); backoff *= 2; continue\n",
    "                        return None\n",
    "                    except requests.RequestException:\n",
    "                        if attempt < MAX_RETRY:\n",
    "                            time.sleep(backoff); backoff *= 2; continue\n",
    "                        return None\n",
    "\n",
    "            # First attempt: as-is\n",
    "            payload = _try_one(sym)\n",
    "            calls_in_window += 1\n",
    "\n",
    "            hit_symbol = None\n",
    "            rec = {k: None for k in KEEP_COLS}\n",
    "            if payload and len(payload) > 0:\n",
    "                hit_symbol = payload[0].get(\"symbol\")\n",
    "                for k in KEEP_COLS:\n",
    "                    rec[k] = payload[0].get(k)\n",
    "\n",
    "            # If empty, try the variant (dot<->hyphen) once (counts toward budget)\n",
    "            if hit_symbol is None:\n",
    "                alt = swap_variant(sym)\n",
    "                if alt != sym:\n",
    "                    # rate limit guard again if needed\n",
    "                    now = time.time()\n",
    "                    elapsed = now - window_start\n",
    "                    if calls_in_window >= calls_per_min and elapsed < 60:\n",
    "                        sleep_for = 60 - elapsed\n",
    "                        print(f\"Pausing {sleep_for:.1f}s to respect {calls_per_min}/min (done {i-1}/{len(symbols)})\")\n",
    "                        time.sleep(sleep_for)\n",
    "                        window_start = time.time()\n",
    "                        calls_in_window = 0\n",
    "\n",
    "                    payload2 = _try_one(alt)\n",
    "                    calls_in_window += 1\n",
    "                    if payload2 and len(payload2) > 0:\n",
    "                        hit_symbol = payload2[0].get(\"symbol\")\n",
    "                        for k in KEEP_COLS:\n",
    "                            rec[k] = payload2[0].get(k)\n",
    "\n",
    "            # assemble output row\n",
    "            rec_out = {\n",
    "                \"queried_symbol\": sym,\n",
    "                \"hit_symbol\": hit_symbol\n",
    "            }\n",
    "            rec_out.update(rec)\n",
    "            rows.append(rec_out)\n",
    "\n",
    "            if i % 100 == 0 or i == len(symbols):\n",
    "                print(f\"Fetched {i}/{len(symbols)}\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if \"cik\" in df.columns:\n",
    "        df = df.rename(columns={\"cik\": \"CIK\"})\n",
    "    # prefer the API's reported symbol if present, else keep queried\n",
    "    df[\"symbol\"] = df[\"hit_symbol\"].fillna(df[\"queried_symbol\"])\n",
    "    # drop exact dupes if any\n",
    "    df = df.drop_duplicates(subset=[\"symbol\"], keep=\"last\")\n",
    "    return df[[\"symbol\", \"companyName\", \"sector\", \"currency\", \"isActivelyTrading\", \"CIK\", \"queried_symbol\", \"hit_symbol\"]]\n",
    "\n",
    "# --- Run it ---\n",
    "profiles_df = fetch_profiles_for_latest(long_latest, calls_per_min=290)\n",
    "print(\"Profiles fetched:\", len(profiles_df))\n",
    "print(profiles_df.head())\n",
    "\n",
    "# (Optional) Save or join\n",
    "# profiles_df.to_parquet(\"profiles_latest.parquet\", index=False)\n",
    "# long_latest_enriched = long_latest.merge(profiles_df.rename(columns={\"symbol\":\"ticker_latest\"}),\n",
    "#                                          on=\"ticker_latest\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrich Daily Membership Rows with Company Profiles (Robust Join)\n",
    "\n",
    "This block **joins profile metadata** (from your 290/min fetcher) onto the daily\n",
    "membership table, handling symbol normalization and **fallback matching**.\n",
    "\n",
    "### Inputs\n",
    "- **`long_df`** (or `long_latest`): daily rows with at least  \n",
    "  `['date', 'ticker_membership', 'ticker_latest']`\n",
    "- **`profiles_df`**: one row per fetched profile with  \n",
    "  `['queried_symbol','hit_symbol','symbol','companyName','sector','currency','isActivelyTrading','CIK']`\n",
    "\n",
    "### What it does\n",
    "1. **Select & normalize the source**  \n",
    "   - If `long_latest` exists, use it; else expect `long_df`.  \n",
    "   - Uppercase/trim `ticker_latest` → `ticker_latest_norm`.  \n",
    "   - Uppercase/trim `profiles_df.queried_symbol` and `.hit_symbol` → normalized keys.\n",
    "\n",
    "2. **Primary join (exact to what you queried)**  \n",
    "   - Join `long_df.ticker_latest_norm` to `profiles_df.queried_symbol_norm`.  \n",
    "   - This matches the symbol you actually asked the API for.\n",
    "\n",
    "3. **Fallback backfill (match the API’s returned symbol)**  \n",
    "   - If the primary join missed (`companyName` is null), try joining\n",
    "     `ticker_latest_norm` to `profiles_df.hit_symbol_norm`.  \n",
    "   - **Coalesce** profile columns from this secondary join only where the primary\n",
    "     result is missing.\n",
    "\n",
    "4. **Tidy the output**\n",
    "   - Rename API-returned `symbol` → `profile_symbol` (so you can compare to\n",
    "     `ticker_latest`).  \n",
    "   - Keep a clean, analyst-friendly column order.\n",
    "\n",
    "5. **Coverage stats**\n",
    "   - Prints how many daily rows now have a `companyName` (quick sanity check).  \n",
    "   - Shows examples of remaining misses.\n",
    "\n",
    "### Output\n",
    "- **`long_with_profiles`** with columns:\n",
    "  - `date`, `ticker_membership`, `ticker_latest`\n",
    "  - `profile_symbol`, `companyName`, `sector`, `currency`, `isActivelyTrading`, `CIK`\n",
    "  - `queried_symbol`, `hit_symbol` (for traceability)\n",
    "\n",
    "### Why both `queried_symbol` and `hit_symbol`?\n",
    "APIs may **normalize** or **redirect** symbols (e.g., dot ↔ hyphen, legacy ↔ current).\n",
    "Keeping both lets you audit mismatches (what you asked vs. what FMP says is canonical).\n",
    "\n",
    "### Practical tips\n",
    "- If coverage is low, inspect misses printed at the end—often they’re symbols\n",
    "  needing dot/hyphen swaps or were never returned by the profile endpoint.\n",
    "- Use `CIK` for **entity-stable joins** across time; use `profile_symbol` / `ticker_latest`\n",
    "  for **display** and **endpoint calls** that expect current naming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile coverage: 2,146,085/2,207,446  (97.2%)\n",
      "Missing examples:\n",
      "             date ticker_membership ticker_latest\n",
      "230926 2024-06-23                                \n",
      "231429 2024-06-22                                \n",
      "231932 2024-06-21                                \n",
      "232435 2024-06-20                                \n",
      "232938 2024-06-19                                \n",
      "233441 2024-06-18                                \n",
      "233944 2024-06-17                                \n",
      "234447 2024-06-16                                \n",
      "234950 2024-06-15                                \n",
      "235453 2024-06-14                                \n"
     ]
    }
   ],
   "source": [
    "# --- prerequisites:\n",
    "# long_df: your daily rows. Ideally has ['date','ticker_membership','ticker_latest'].\n",
    "# profiles_df: from the 290/min fetcher, with columns including ['queried_symbol','hit_symbol',\n",
    "#               'symbol','companyName','sector','currency','isActivelyTrading','CIK'].\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1) normalize join keys\n",
    "def _up(s): \n",
    "    return None if pd.isna(s) else str(s).strip().upper()\n",
    "\n",
    "# pick the right long table (supports either variable name)\n",
    "if 'long_latest' in globals():\n",
    "    long_df = long_latest.copy()\n",
    "else:\n",
    "    long_df = long_df.copy()  # if your variable is already named long_df\n",
    "\n",
    "# ensure key exists\n",
    "if \"ticker_latest\" not in long_df.columns:\n",
    "    raise ValueError(\"long_df must contain a 'ticker_latest' column (the symbol you queried for profiles).\")\n",
    "\n",
    "left = long_df.copy()\n",
    "left[\"ticker_latest_norm\"] = left[\"ticker_latest\"].map(_up)\n",
    "\n",
    "prof = profiles_df.copy()\n",
    "prof[\"queried_symbol_norm\"] = prof[\"queried_symbol\"].map(_up)\n",
    "prof[\"hit_symbol_norm\"]     = prof[\"hit_symbol\"].map(_up)\n",
    "\n",
    "# 2) primary join: ticker_latest == queried_symbol\n",
    "m1 = left.merge(\n",
    "    prof.rename(columns={\"queried_symbol_norm\":\"join_key\"}),\n",
    "    left_on=\"ticker_latest_norm\",\n",
    "    right_on=\"join_key\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_prof\")\n",
    ")\n",
    "\n",
    "# 3) optional backfill: if queried_symbol missed but hit_symbol matches\n",
    "miss_mask = m1[\"companyName\"].isna() & prof[\"hit_symbol_norm\"].notna().any()\n",
    "if miss_mask.any():\n",
    "    prof2 = prof.rename(columns={\"hit_symbol_norm\":\"join_key\"})\n",
    "    m2 = left.merge(\n",
    "        prof2,\n",
    "        left_on=\"ticker_latest_norm\",\n",
    "        right_on=\"join_key\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_hit\")\n",
    "    )\n",
    "    # coalesce profile columns from m2 where m1 is missing\n",
    "    for col in [\"symbol\",\"companyName\",\"sector\",\"currency\",\"isActivelyTrading\",\"CIK\",\n",
    "                \"queried_symbol\",\"hit_symbol\"]:\n",
    "        if col in m1.columns and col in m2.columns:\n",
    "            m1[col] = m1[col].combine_first(m2[col])\n",
    "\n",
    "# 4) tidy output\n",
    "long_with_profiles = (\n",
    "    m1.drop(columns=[c for c in m1.columns if c.endswith(\"_prof\") or c == \"join_key\"])\n",
    "      .rename(columns={\n",
    "          \"symbol\": \"profile_symbol\",  # what FMP returned\n",
    "      })\n",
    "      # order columns for convenience\n",
    "      [[\n",
    "          \"date\",\"ticker_membership\",\"ticker_latest\",\n",
    "          \"profile_symbol\",\"companyName\",\"sector\",\"currency\",\"isActivelyTrading\",\"CIK\",\n",
    "          \"queried_symbol\",\"hit_symbol\"\n",
    "      ]]\n",
    ")\n",
    "\n",
    "# 5) quick coverage stats\n",
    "total = len(long_with_profiles)\n",
    "have  = long_with_profiles[\"companyName\"].notna().sum()\n",
    "print(f\"Profile coverage: {have:,}/{total:,}  ({have/total:.1%})\")\n",
    "print(\"Missing examples:\")\n",
    "print(long_with_profiles[long_with_profiles[\"companyName\"].isna()]\n",
    "      [[\"date\",\"ticker_membership\",\"ticker_latest\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker_membership</th>\n",
       "      <th>ticker_latest</th>\n",
       "      <th>profile_symbol</th>\n",
       "      <th>companyName</th>\n",
       "      <th>sector</th>\n",
       "      <th>currency</th>\n",
       "      <th>isActivelyTrading</th>\n",
       "      <th>CIK</th>\n",
       "      <th>queried_symbol</th>\n",
       "      <th>hit_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc.</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0001090872</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0000320193</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0001551152</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>Airbnb, Inc.</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0001559720</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-26</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0000001800</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207441</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>YHOO</td>\n",
       "      <td>YHOO</td>\n",
       "      <td>YHOO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>YHOO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207442</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>YUM</td>\n",
       "      <td>YUM</td>\n",
       "      <td>YUM</td>\n",
       "      <td>Yum! Brands, Inc.</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0001041061</td>\n",
       "      <td>YUM</td>\n",
       "      <td>YUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207443</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>ZBH</td>\n",
       "      <td>ZBH</td>\n",
       "      <td>ZBH</td>\n",
       "      <td>Zimmer Biomet Holdings, Inc.</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0001136869</td>\n",
       "      <td>ZBH</td>\n",
       "      <td>ZBH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207444</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>ZION</td>\n",
       "      <td>ZION</td>\n",
       "      <td>ZION</td>\n",
       "      <td>Zions Bancorporation, National Association</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0000109380</td>\n",
       "      <td>ZION</td>\n",
       "      <td>ZION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207445</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis Inc.</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0001555280</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2207446 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date ticker_membership ticker_latest profile_symbol  \\\n",
       "0       2025-09-26                 A             A              A   \n",
       "1       2025-09-26              AAPL          AAPL           AAPL   \n",
       "2       2025-09-26              ABBV          ABBV           ABBV   \n",
       "3       2025-09-26              ABNB          ABNB           ABNB   \n",
       "4       2025-09-26               ABT           ABT            ABT   \n",
       "...            ...               ...           ...            ...   \n",
       "2207441 2013-09-26              YHOO          YHOO           YHOO   \n",
       "2207442 2013-09-26               YUM           YUM            YUM   \n",
       "2207443 2013-09-26               ZBH           ZBH            ZBH   \n",
       "2207444 2013-09-26              ZION          ZION           ZION   \n",
       "2207445 2013-09-26               ZTS           ZTS            ZTS   \n",
       "\n",
       "                                        companyName              sector  \\\n",
       "0                        Agilent Technologies, Inc.          Healthcare   \n",
       "1                                        Apple Inc.          Technology   \n",
       "2                                       AbbVie Inc.          Healthcare   \n",
       "3                                      Airbnb, Inc.   Consumer Cyclical   \n",
       "4                               Abbott Laboratories          Healthcare   \n",
       "...                                             ...                 ...   \n",
       "2207441                                         NaN                 NaN   \n",
       "2207442                           Yum! Brands, Inc.   Consumer Cyclical   \n",
       "2207443                Zimmer Biomet Holdings, Inc.          Healthcare   \n",
       "2207444  Zions Bancorporation, National Association  Financial Services   \n",
       "2207445                                 Zoetis Inc.          Healthcare   \n",
       "\n",
       "        currency isActivelyTrading         CIK queried_symbol hit_symbol  \n",
       "0            USD              True  0001090872              A          A  \n",
       "1            USD              True  0000320193           AAPL       AAPL  \n",
       "2            USD              True  0001551152           ABBV       ABBV  \n",
       "3            USD              True  0001559720           ABNB       ABNB  \n",
       "4            USD              True  0000001800            ABT        ABT  \n",
       "...          ...               ...         ...            ...        ...  \n",
       "2207441      NaN               NaN        None           YHOO        NaN  \n",
       "2207442      USD              True  0001041061            YUM        YUM  \n",
       "2207443      USD              True  0001136869            ZBH        ZBH  \n",
       "2207444      USD              True  0000109380           ZION       ZION  \n",
       "2207445      USD              True  0001555280            ZTS        ZTS  \n",
       "\n",
       "[2207446 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_with_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DF shape: (2146085, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>latest_ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>sector</th>\n",
       "      <th>currency</th>\n",
       "      <th>is_actively_trading</th>\n",
       "      <th>cik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies, Inc.</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0001090872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0001675149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0000320193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0001551152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>USD</td>\n",
       "      <td>True</td>\n",
       "      <td>0000001800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker latest_ticker                company_name  \\\n",
       "0  2013-09-26      A             A  Agilent Technologies, Inc.   \n",
       "1  2013-09-26     AA            AA           Alcoa Corporation   \n",
       "2  2013-09-26   AAPL          AAPL                  Apple Inc.   \n",
       "3  2013-09-26   ABBV          ABBV                 AbbVie Inc.   \n",
       "4  2013-09-26    ABT           ABT         Abbott Laboratories   \n",
       "\n",
       "            sector currency is_actively_trading         cik  \n",
       "0       Healthcare      USD                True  0001090872  \n",
       "1  Basic Materials      USD                True  0001675149  \n",
       "2       Technology      USD                True  0000320193  \n",
       "3       Healthcare      USD                True  0001551152  \n",
       "4       Healthcare      USD                True  0000001800  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start from long_with_profiles\n",
    "import pandas as pd\n",
    "\n",
    "cols_keep = [\n",
    "    \"date\", \"ticker_membership\", \"ticker_latest\",\n",
    "    \"companyName\", \"sector\", \"currency\", \"isActivelyTrading\", \"CIK\"\n",
    "]\n",
    "\n",
    "df = long_with_profiles[cols_keep].copy()\n",
    "\n",
    "# 1) Drop true NAs *before* any string casting\n",
    "#    (rows with no profile info — e.g., the ~50 delisted)\n",
    "df = df.dropna(subset=[\"companyName\"])             # or add \"CIK\" too if you want: [\"companyName\",\"CIK\"]\n",
    "\n",
    "# 2) Rename to snake_case\n",
    "df = df.rename(columns={\n",
    "    \"ticker_membership\": \"ticker\",\n",
    "    \"ticker_latest\": \"latest_ticker\",\n",
    "    \"companyName\": \"company_name\",\n",
    "    \"isActivelyTrading\": \"is_actively_trading\",\n",
    "    \"CIK\": \"cik\",\n",
    "})\n",
    "\n",
    "# 3) Clean types without turning NAs into strings\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\").dt.date\n",
    "text_cols = [\"ticker\", \"latest_ticker\", \"company_name\", \"sector\", \"currency\", \"cik\"]\n",
    "for c in text_cols:\n",
    "    df[c] = df[c].astype(\"string\").str.strip()\n",
    "\n",
    "# (optional) guard against any leftover literal 'nan'/'none'/''\n",
    "for c in text_cols:\n",
    "    df.loc[df[c].str.lower().isin([\"nan\",\"none\",\"\"]), c] = pd.NA\n",
    "\n",
    "# 4) Dedupe per (date, ticker)\n",
    "df = (df.sort_values([\"date\",\"ticker\",\"latest_ticker\"])\n",
    "        .drop_duplicates(subset=[\"date\",\"ticker\"], keep=\"last\")\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "print(\"Final DF shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Enriched Membership Data to PostgreSQL\n",
    "\n",
    "This block writes the **daily membership + profiles table** into a Postgres\n",
    "database (`sp500_long_latest_profiles`) with explicit column types and indexes.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Database connection**\n",
    "   - Creates a SQLAlchemy engine:\n",
    "     ```python\n",
    "     engine = create_engine(\"postgresql://postgres:CSDBMS623@localhost:5432/SP500_ML\")\n",
    "     ```\n",
    "   - Update the string if your username, password, host, port, or database name differ.\n",
    "\n",
    "2. **Write DataFrame → SQL table**\n",
    "   - Uses `df.to_sql()` with:\n",
    "     - `if_exists=\"replace\"` → drops and recreates the table each run  \n",
    "       (switch to `\"append\"` if you want to accumulate instead).\n",
    "     - `method=\"multi\"`, `chunksize=10_000` for efficient bulk inserts.\n",
    "     - Explicit Postgres column types (`DATE`, `VARCHAR`, `BOOLEAN`) for schema control.\n",
    "\n",
    "   - Expected DataFrame schema:\n",
    "     - `date` (`DATE`)\n",
    "     - `ticker` (original symbol from membership)\n",
    "     - `latest_ticker` (canonicalized symbol)\n",
    "     - `company_name`, `sector`, `currency`\n",
    "     - `is_actively_trading` (`BOOLEAN`)\n",
    "     - `cik` (company identifier)\n",
    "\n",
    "3. **Add keys and indexes**\n",
    "   - Declares `(date, ticker)` as the composite primary key → prevents duplicates.\n",
    "   - Adds indexes to speed up joins/queries:\n",
    "     - By `latest_ticker` (common join key).\n",
    "     - By `cik` (stable company identifier).\n",
    "\n",
    "### Output\n",
    "- A fully materialized table `sp500_long_latest_profiles` in Postgres with:\n",
    "  - One row per `(date, ticker)`\n",
    "  - Enriched profile data aligned to each ticker\n",
    "  - Primary key and helpful indexes for performance\n",
    "\n",
    "### Notes\n",
    "- **Replace vs. Append**:  \n",
    "  Use `\"replace\"` while iterating/testing; switch to `\"append\"` for incremental loads.\n",
    "- **Schema safety**:  \n",
    "  Explicit types ensure Postgres doesn’t infer overly long `TEXT` or mis-handle booleans.\n",
    "- **Indexes**:  \n",
    "  Optional but recommended—improves lookup when joining with price/fundamental tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2146085"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(\"postgresql://postgres:CSDBMS623@localhost:5432/SP500_ML\")\n",
    "table_name = \"sp500_long_latest_profiles\"\n",
    "\n",
    "required_cols = [\n",
    "    \"date\",\"ticker\",\"latest_ticker\",\"company_name\",\"sector\",\n",
    "    \"currency\",\"is_actively_trading\",\"cik\"\n",
    "]\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"df missing required columns: {missing}\")\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # 1) create table if needed (first run)\n",
    "    conn.execute(text(f'''\n",
    "        CREATE TABLE IF NOT EXISTS \"{table_name}\" (\n",
    "            date DATE NOT NULL,\n",
    "            ticker VARCHAR(16) NOT NULL,\n",
    "            latest_ticker VARCHAR(16),\n",
    "            company_name VARCHAR(256),\n",
    "            sector VARCHAR(64),\n",
    "            currency VARCHAR(8),\n",
    "            is_actively_trading BOOLEAN,\n",
    "            cik VARCHAR(16)\n",
    "        );\n",
    "    '''))\n",
    "\n",
    "    # 2) add PK only if table has NO primary key yet\n",
    "    pk_exists = conn.execute(text(f\"\"\"\n",
    "        SELECT EXISTS (\n",
    "          SELECT 1\n",
    "          FROM pg_constraint\n",
    "          WHERE conrelid = 'public.{table_name}'::regclass\n",
    "            AND contype  = 'p'\n",
    "        );\n",
    "    \"\"\")).scalar()\n",
    "\n",
    "    if not pk_exists:\n",
    "        conn.execute(text(f'''\n",
    "            ALTER TABLE \"public\".\"{table_name}\"\n",
    "            ADD CONSTRAINT pk_{table_name} PRIMARY KEY (date, ticker);\n",
    "        '''))\n",
    "\n",
    "    # 3) helpful indexes\n",
    "    conn.execute(text(f'CREATE INDEX IF NOT EXISTS idx_{table_name}_latest ON \"public\".\"{table_name}\" (latest_ticker);'))\n",
    "    conn.execute(text(f'CREATE INDEX IF NOT EXISTS idx_{table_name}_cik    ON \"public\".\"{table_name}\" (cik);'))\n",
    "\n",
    "    # 4) replace data without dropping table (keeps dependent views intact)\n",
    "    conn.execute(text(f'TRUNCATE TABLE \"public\".\"{table_name}\";'))\n",
    "\n",
    "# 5) bulk insert\n",
    "df[required_cols].to_sql(\n",
    "    table_name,\n",
    "    engine,\n",
    "    if_exists=\"append\",\n",
    "    index=False,\n",
    "    method=\"multi\",\n",
    "    chunksize=10_000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
